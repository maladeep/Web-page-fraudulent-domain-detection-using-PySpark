{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f899fe3-dc42-4d26-8587-e1e3206d3b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession  # For creating a Spark session\n",
    "from pyspark.ml.feature import VectorAssembler, ChiSqSelector  # For classes for feature engineering\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, NaiveBayes, LinearSVC, GBTClassifier  # For classification algorithms\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator  # For classes for model evaluation\n",
    "from pyspark.ml import Pipeline  # For Pipeline class for creating a sequence of stages\n",
    "from pyspark.ml.feature import StringIndexer  # For StringIndexer for indexing categorical target variable\n",
    "\n",
    "import matplotlib.pyplot as plt  # For visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb80976f-0097-4f54-ab55-8f20dca4d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a Spark session\n",
    "spark_session = SparkSession.builder.appName(\"URLClassification\").getOrCreate()\n",
    "\n",
    "# Loading the data\n",
    "data = spark_session.read.csv(\"dataset_phishing.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5a4286-888a-471f-90be-32f40c694c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/30 21:24:30 WARN Utils: Your hostname, MDUs-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.18.2 instead (on interface en0)\n",
      "23/08/30 21:24:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/30 21:24:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DecisionTree without ChiSqSelector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/30 21:24:36 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RandomForest without ChiSqSelector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java HotSpot(TM) 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeCache: size=131072Kb used=42612Kb max_used=42863Kb free=88459Kb\n",
      " bounds [0x000000010421c000, 0x0000000106c4c000, 0x000000010c21c000]\n",
      " total_blobs=14970 nmethods=13911 adapters=970\n",
      " compilation: disabled (not enough contiguous free space left)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/30 21:24:43 WARN DAGScheduler: Broadcasting large task binary with size 1048.8 KiB\n",
      "23/08/30 21:24:43 WARN DAGScheduler: Broadcasting large task binary with size 1665.8 KiB\n",
      "23/08/30 21:24:44 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/08/30 21:24:45 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "23/08/30 21:24:46 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n",
      "23/08/30 21:24:47 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/08/30 21:24:48 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/08/30 21:24:48 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/08/30 21:24:49 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NaiveBayes without ChiSqSelector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/30 21:24:51 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing GBT without ChiSqSelector...\n",
      "Processing LinearSVC without ChiSqSelector...\n",
      "Processing DecisionTree with ChiSqSelector...\n",
      "Confusion matrix for DecisionTree:\n",
      "DataFrame[label: double, 0.0: bigint, 1.0: bigint]\n",
      "Processing RandomForest with ChiSqSelector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/30 21:25:08 WARN DAGScheduler: Broadcasting large task binary with size 1048.8 KiB\n",
      "23/08/30 21:25:09 WARN DAGScheduler: Broadcasting large task binary with size 1665.8 KiB\n",
      "23/08/30 21:25:09 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/08/30 21:25:10 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "23/08/30 21:25:11 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n",
      "23/08/30 21:25:12 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/08/30 21:25:13 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/08/30 21:25:13 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/08/30 21:25:14 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/08/30 21:25:14 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/08/30 21:25:14 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/08/30 21:25:14 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/08/30 21:25:15 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for RandomForest:\n",
      "DataFrame[label: double, 0.0: bigint, 1.0: bigint]\n",
      "Processing NaiveBayes with ChiSqSelector...\n",
      "Confusion matrix for NaiveBayes:\n",
      "DataFrame[label: double, 0.0: bigint, 1.0: bigint]\n",
      "Processing GBT with ChiSqSelector...\n",
      "Confusion matrix for GBT:\n",
      "DataFrame[label: double, 0.0: bigint, 1.0: bigint]\n",
      "Processing LinearSVC with ChiSqSelector...\n",
      "Confusion matrix for LinearSVC:\n",
      "DataFrame[label: double, 0.0: bigint, 1.0: bigint]\n",
      "+------------+--------------------+----+-----+--------+--------+\n",
      "|  Classifier|   Feature Selection| AUC|AUPRC|Accuracy|F1-score|\n",
      "+------------+--------------------+----+-----+--------+--------+\n",
      "|DecisionTree|Without ChiSqSele...| 0.9| 0.93|    0.92|    0.92|\n",
      "|RandomForest|Without ChiSqSele...|0.99| 0.99|    0.96|    0.96|\n",
      "|  NaiveBayes|Without ChiSqSele...|0.65| 0.68|    0.76|    0.76|\n",
      "|         GBT|Without ChiSqSele...|0.98| 0.98|    0.93|    0.93|\n",
      "|   LinearSVC|Without ChiSqSele...|0.98| 0.98|    0.94|    0.94|\n",
      "|DecisionTree|  With ChiSqSelector| 0.9| 0.93|    0.92|    0.92|\n",
      "|RandomForest|  With ChiSqSelector|0.99| 0.99|    0.96|    0.96|\n",
      "|  NaiveBayes|  With ChiSqSelector|0.65| 0.68|    0.76|    0.76|\n",
      "|         GBT|  With ChiSqSelector|0.98| 0.98|    0.93|    0.93|\n",
      "|   LinearSVC|  With ChiSqSelector|0.98| 0.98|    0.94|    0.94|\n",
      "+------------+--------------------+----+-----+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# list of feature columns\n",
    "feature_cols = ['length_url', 'length_hostname', 'ip', 'nb_dots', 'nb_hyphens', 'nb_at', 'nb_qm', \n",
    "                'nb_and', 'nb_or', 'nb_eq', 'nb_underscore', 'nb_tilde', 'nb_percent', 'nb_slash', \n",
    "                'nb_star', 'nb_colon', 'nb_comma', 'nb_semicolumn', 'nb_dollar', 'nb_space', \n",
    "                'nb_www', 'nb_com', 'nb_dslash', 'http_in_path', 'https_token', 'ratio_digits_url', \n",
    "                'ratio_digits_host', 'punycode', 'port', 'tld_in_path', 'tld_in_subdomain', \n",
    "                'abnormal_subdomain', 'nb_subdomains', 'prefix_suffix', 'random_domain', \n",
    "                'shortening_service', 'path_extension', 'nb_redirection', 'nb_external_redirection', \n",
    "                'length_words_raw', 'char_repeat', 'shortest_words_raw', 'shortest_word_host', \n",
    "                'shortest_word_path', 'longest_words_raw', 'longest_word_host', 'longest_word_path', \n",
    "                'avg_words_raw', 'avg_word_host', 'avg_word_path', 'phish_hints', 'domain_in_brand', \n",
    "                'brand_in_subdomain', 'brand_in_path', 'suspecious_tld', 'statistical_report', \n",
    "                'nb_hyperlinks', 'ratio_intHyperlinks', 'ratio_extHyperlinks', 'ratio_nullHyperlinks', \n",
    "                'nb_extCSS', 'ratio_intRedirection', 'ratio_extRedirection', 'ratio_intErrors', \n",
    "                'ratio_extErrors', 'login_form', 'external_favicon', 'links_in_tags', 'submit_email', \n",
    "                'ratio_intMedia', 'ratio_extMedia', 'sfh', 'iframe', 'popup_window', 'safe_anchor', \n",
    "                'onmouseover', 'right_clic', 'empty_title', 'domain_in_title', 'domain_with_copyright', \n",
    "                'whois_registered_domain', 'domain_registration_length', 'domain_age', 'web_traffic', \n",
    "                'dns_record', 'google_index', 'page_rank']\n",
    "\n",
    "# Target indexer\n",
    "target_indexer = StringIndexer(inputCol=\"status\", outputCol=\"label\")\n",
    "\n",
    "# Creating a VectorAssembler for the feature columns\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# List of Classifiers\n",
    "classifiers = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\"),\n",
    "    \"RandomForest\": RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100, maxDepth=10),\n",
    "    \"NaiveBayes\": NaiveBayes(smoothing=1.0, modelType=\"gaussian\"),\n",
    "    \"GBT\": GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10),\n",
    "    \"LinearSVC\": LinearSVC(labelCol=\"label\", featuresCol=\"features\")\n",
    "}\n",
    "\n",
    "# Empty list to store evaluation results\n",
    "evaluation_results = []\n",
    "\n",
    "# Everything loop for classifier\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    print(f\"Processing {classifier_name} without ChiSqSelector...\")\n",
    "\n",
    "    # Creating a pipeline\n",
    "    pipeline = Pipeline(stages=[target_indexer, assembler, classifier])\n",
    "\n",
    "    # Spliting the data into training and testing sets\n",
    "    train_data, test_data = data.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "    # Training the model\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    # Making predictions on the test data\n",
    "    predictions = model.transform(test_data)\n",
    "\n",
    "    # Evaluating the model using different metrics\n",
    "    evaluator_roc = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "    auc = round(evaluator_roc.evaluate(predictions), 2)\n",
    "\n",
    "    evaluator_pr = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderPR\")\n",
    "    auprc = round(evaluator_pr.evaluate(predictions), 2)\n",
    "\n",
    "    evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "    accuracy = round(eval uator_acc.evaluate(predictions), 2)\n",
    "\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"f1\")\n",
    "    f1 = round(evaluator_f1.evaluate(predictions), 2)\n",
    "\n",
    "    # Appending the evaluation results to the list\n",
    "    evaluation_results.append((classifier_name, \"Without ChiSqSelector\", auc, auprc, accuracy, f1))\n",
    "\n",
    "# Loop through each classifier again\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    print(f\"Processing {classifier_name} with ChiSqSelector...\")\n",
    "\n",
    "    # Creating a pipeline with ChiSqSelector\n",
    "    selector = ChiSqSelector(numTopFeatures=10, featuresCol=\"features\", outputCol=\"selected_features\")\n",
    "    pipeline = Pipeline(stages=[target_indexer, assembler, selector, classifier])\n",
    "\n",
    "    # Spliting the data into training and testing sets\n",
    "    train_data, test_data = data.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "    # Training the model\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    # Save the RandomForest model\n",
    "    # if classifier_name == \"RandomForest\":\n",
    "    #     rf_classifier = classifier\n",
    "    #     pipeline_rf = Pipeline(stages=[target_indexer, assembler, rf_classifier])\n",
    "    #     model_rf = pipeline_rf.fit(train_data)\n",
    "    #     model_rf.save(\"random_forest_model\")\n",
    "\n",
    "    # Making predictions on the test data\n",
    "    predictions = model.transform(test_data)\n",
    "\n",
    "    # Evaluating the model using different metrics\n",
    "    evaluator_roc = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "    auc = round(evaluator_roc.evaluate(predictions), 2)\n",
    "\n",
    "    evaluator_pr = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderPR\")\n",
    "    auprc = round(evaluator_pr.evaluate(predictions), 2)\n",
    "\n",
    "    evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "    accuracy = round(evaluator_acc.evaluate(predictions), 2)\n",
    "\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"f1\")\n",
    "    f1 = round(evaluator_f1.evaluate(predictions), 2)\n",
    "\n",
    "    # Appending the evaluation results to the list\n",
    "    evaluation_results.append((classifier_name, \"With ChiSqSelector\", auc, auprc, accuracy, f1))\n",
    "\n",
    "    # Creating a MulticlassClassificationEvaluator\n",
    "    evaluator_multiclass = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "    # Calculating confusion matrix\n",
    "    confusion_matrix = predictions.groupBy(\"label\").pivot(\"prediction\").count().na.fill(0).orderBy(\"label\")\n",
    "    print(f\"Confusion matrix for {classifier_name}:\\n{confusion_matrix}\")\n",
    "\n",
    "# Creating a DataFrame from the list of evaluation results\n",
    "summary_schema = [\"Classifier\", \"Feature Selection\", \"AUC\", \"AUPRC\", \"Accuracy\", \"F1-score\"]\n",
    "summary_df = spark_session.createDataFrame(evaluation_results, summary_schema)\n",
    "\n",
    "# Showing the summary table\n",
    "summary_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10d051-b665-4ecf-b71c-eb4ad648206a",
   "metadata": {},
   "source": [
    " - RandomForest classifier is performing the best among the tested classifiers with or without feature selection.\n",
    " - With and without feature selection the result are same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda4dab9-3426-468e-80ac-72a28816cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrices:\n",
      "\n",
      "Classifier: DecisionTree\n",
      "+-----+----+----+\n",
      "|label| 0.0| 1.0|\n",
      "+-----+----+----+\n",
      "|  0.0|1634| 110|\n",
      "|  1.0|  95|1673|\n",
      "+-----+----+----+\n",
      "\n",
      "\n",
      "Classifier: RandomForest\n",
      "+-----+----+----+\n",
      "|label| 0.0| 1.0|\n",
      "+-----+----+----+\n",
      "|  0.0|1634| 110|\n",
      "|  1.0|  95|1673|\n",
      "+-----+----+----+\n",
      "\n",
      "\n",
      "Classifier: NaiveBayes\n",
      "+-----+----+----+\n",
      "|label| 0.0| 1.0|\n",
      "+-----+----+----+\n",
      "|  0.0|1634| 110|\n",
      "|  1.0|  95|1673|\n",
      "+-----+----+----+\n",
      "\n",
      "\n",
      "Classifier: GBT\n",
      "+-----+----+----+\n",
      "|label| 0.0| 1.0|\n",
      "+-----+----+----+\n",
      "|  0.0|1634| 110|\n",
      "|  1.0|  95|1673|\n",
      "+-----+----+----+\n",
      "\n",
      "\n",
      "Classifier: LinearSVC\n",
      "+-----+----+----+\n",
      "|label| 0.0| 1.0|\n",
      "+-----+----+----+\n",
      "|  0.0|1634| 110|\n",
      "|  1.0|  95|1673|\n",
      "+-----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print confusion matrices for all classifiers in a tabular format\n",
    "print(\"\\nConfusion Matrices:\")\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    print(f\"\\nClassifier: {classifier_name}\")\n",
    "    confusion_matrix = predictions.groupBy(\"label\").pivot(\"prediction\").count().na.fill(0).orderBy(\"label\")\n",
    "    \n",
    "    confusion_matrix.show()\n",
    "\n",
    "# # Stop the Spark session\n",
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e3e72c-fb4a-4520-8469-475a6a16c86c",
   "metadata": {},
   "source": [
    "- As all model have confusion matrix is also same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0e800-3718-45fd-bfba-19f7aa280c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
